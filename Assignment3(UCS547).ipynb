{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQRQbLcSFWRSQxtRpKnox+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinavmarkanda/UCS547-Accelerated-Data-Science/blob/main/Assignment3(UCS547).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR789GHHPTID",
        "outputId": "c9f502ba-fc42-41ad-ba9c-1ba133cb416b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing vector_add.cu\n"
          ]
        }
      ],
      "source": [
        "##Q1\n",
        "%%writefile vector_add.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 1024\n",
        "\n",
        "__global__ void vectorAdd(float *A, float *B, float *C, int n)\n",
        "{\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n)\n",
        "    {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    float *h_A, *h_B, *h_C;\n",
        "    float *d_A, *d_B, *d_C;\n",
        "\n",
        "    size_t size = N * sizeof(float);\n",
        "\n",
        "    // Allocate host memory\n",
        "    h_A = (float*)malloc(size);\n",
        "    h_B = (float*)malloc(size);\n",
        "    h_C = (float*)malloc(size);\n",
        "\n",
        "    // Initialize vectors\n",
        "    for (int i = 0; i < N; i++)\n",
        "    {\n",
        "        h_A[i] = i * 1.0f;\n",
        "        h_B[i] = i * 2.0f;\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    // Copy to device\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, N);\n",
        "\n",
        "    // Copy result back\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"First 10 elements:\\n\");\n",
        "    for (int i = 0; i < 10; i++)\n",
        "    {\n",
        "        printf(\"C[%d] = %f\\n\", i, h_C[i]);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc vector_add.cu -o vector_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usIEXwbCPyT7",
        "outputId": "4c4977e4-c530-46e9-a38e-db2023949f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : Support for offline compilation for architectures prior to '<compute/sm/lto>_75' will be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaawrzfDQFB1",
        "outputId": "364c0b11-486c-48a2-b2a3-ea76684ddc79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 elements:\n",
            "C[0] = 0.000000\n",
            "C[1] = 3.000000\n",
            "C[2] = 6.000000\n",
            "C[3] = 9.000000\n",
            "C[4] = 12.000000\n",
            "C[5] = 15.000000\n",
            "C[6] = 18.000000\n",
            "C[7] = 21.000000\n",
            "C[8] = 24.000000\n",
            "C[9] = 27.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Q2\n",
        "%%writefile thrust_vector_add.cu\n",
        "#include <iostream>\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/transform.h>\n",
        "#include <thrust/functional.h>\n",
        "\n",
        "#define N 1024\n",
        "\n",
        "int main()\n",
        "{\n",
        "    // Create host vectors\n",
        "    thrust::host_vector<float> h_A(N);\n",
        "    thrust::host_vector<float> h_B(N);\n",
        "\n",
        "    // Initialize vectors\n",
        "    for(int i = 0; i < N; i++)\n",
        "    {\n",
        "        h_A[i] = i * 1.0f;\n",
        "        h_B[i] = i * 2.0f;\n",
        "    }\n",
        "\n",
        "    // Copy to device vectors\n",
        "    thrust::device_vector<float> d_A = h_A;\n",
        "    thrust::device_vector<float> d_B = h_B;\n",
        "    thrust::device_vector<float> d_C(N);\n",
        "\n",
        "    // Perform vector addition using thrust::plus\n",
        "    thrust::transform(d_A.begin(), d_A.end(),\n",
        "                      d_B.begin(),\n",
        "                      d_C.begin(),\n",
        "                      thrust::plus<float>());\n",
        "\n",
        "    // Copy result back to host\n",
        "    thrust::host_vector<float> h_C = d_C;\n",
        "\n",
        "    // Print first 10 results\n",
        "    std::cout << \"First 10 elements of C:\\n\";\n",
        "    for(int i = 0; i < 10; i++)\n",
        "    {\n",
        "        std::cout << \"C[\" << i << \"] = \" << h_C[i] << std::endl;\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWRh1L7-QJRF",
        "outputId": "af467a0e-997f-4d70-aa45-70d487b77765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing thrust_vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc thrust_vector_add.cu -o thrust_vector_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi7dcUY-QcAD",
        "outputId": "2b50b6e2-42d3-4056-91fb-049f4b552ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : Support for offline compilation for architectures prior to '<compute/sm/lto>_75' will be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./thrust_vector_add\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMkl6xLDQd3Y",
        "outputId": "aa5713cb-6366-4494-f8d9-12fb4de5c815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 elements of C:\n",
            "C[0] = 0\n",
            "C[1] = 3\n",
            "C[2] = 6\n",
            "C[3] = 9\n",
            "C[4] = 12\n",
            "C[5] = 15\n",
            "C[6] = 18\n",
            "C[7] = 21\n",
            "C[8] = 24\n",
            "C[9] = 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Q3\n",
        "%%writefile thrust_dot_product.cu\n",
        "#include <iostream>\n",
        "#include <chrono>\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/inner_product.h>\n",
        "\n",
        "#define N 1024\n",
        "\n",
        "int main()\n",
        "{\n",
        "    // ---------------- CPU PART ----------------\n",
        "    float A[N], B[N];\n",
        "\n",
        "    for(int i = 0; i < N; i++)\n",
        "    {\n",
        "        A[i] = 1.0f;\n",
        "        B[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    float cpu_result = 0.0f;\n",
        "    for(int i = 0; i < N; i++)\n",
        "    {\n",
        "        cpu_result += A[i] * B[i];\n",
        "    }\n",
        "\n",
        "    auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double, std::milli> cpu_time = cpu_end - cpu_start;\n",
        "\n",
        "    // ---------------- GPU PART (THRUST) ----------------\n",
        "\n",
        "    thrust::host_vector<float> h_A(N);\n",
        "    thrust::host_vector<float> h_B(N);\n",
        "\n",
        "    for(int i = 0; i < N; i++)\n",
        "    {\n",
        "        h_A[i] = 1.0f;\n",
        "        h_B[i] = 2.0f;\n",
        "    }\n",
        "\n",
        "    thrust::device_vector<float> d_A = h_A;\n",
        "    thrust::device_vector<float> d_B = h_B;\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    auto gpu_start = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    float gpu_result = thrust::inner_product(\n",
        "                            d_A.begin(),\n",
        "                            d_A.end(),\n",
        "                            d_B.begin(),\n",
        "                            0.0f);\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    auto gpu_end = std::chrono::high_resolution_clock::now();\n",
        "    std::chrono::duration<double, std::milli> gpu_time = gpu_end - gpu_start;\n",
        "\n",
        "    // ---------------- RESULTS ----------------\n",
        "\n",
        "    std::cout << \"Dot Product (CPU)  = \" << cpu_result << std::endl;\n",
        "    std::cout << \"CPU Time (ms)      = \" << cpu_time.count() << std::endl;\n",
        "\n",
        "    std::cout << \"Dot Product (GPU)  = \" << gpu_result << std::endl;\n",
        "    std::cout << \"GPU Time (ms)      = \" << gpu_time.count() << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VS5Bj5sbQg_U",
        "outputId": "0fc60a26-0610-4a1b-d5d5-463f3b447030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting thrust_dot_product.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc thrust_dot_product.cu -o thrust_dot_product\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LijmTqAqQ2Qr",
        "outputId": "67c54541-49be-4cc6-8695-77478fd8df53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc warning : Support for offline compilation for architectures prior to '<compute/sm/lto>_75' will be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./thrust_dot_product\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gNPK_9JQ3uo",
        "outputId": "b8a07b7c-bbf2-45c9-ceb7-b49f577fa5d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dot Product (CPU)  = 2048\n",
            "CPU Time (ms)      = 0.003335\n",
            "Dot Product (GPU)  = 2048\n",
            "GPU Time (ms)      = 1.5498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Q4\n",
        "import numpy as np\n",
        "from numba import cuda\n",
        "\n",
        "# -----------------------------\n",
        "# Matrix size\n",
        "# -----------------------------\n",
        "N = 16\n",
        "\n",
        "# -----------------------------\n",
        "# CUDA Kernel\n",
        "# -----------------------------\n",
        "@cuda.jit\n",
        "def matrixMul(A, B, C):\n",
        "    row, col = cuda.grid(2)\n",
        "\n",
        "    if row < N and col < N:\n",
        "        temp = 0.0\n",
        "        for k in range(N):\n",
        "            temp += A[row, k] * B[k, col]\n",
        "        C[row, col] = temp\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Host Code\n",
        "# -----------------------------\n",
        "# Initialize matrices (same as your C code: all ones)\n",
        "h_A = np.ones((N, N), dtype=np.float32)\n",
        "h_B = np.ones((N, N), dtype=np.float32)\n",
        "h_C = np.zeros((N, N), dtype=np.float32)\n",
        "\n",
        "# Copy to device\n",
        "d_A = cuda.to_device(h_A)\n",
        "d_B = cuda.to_device(h_B)\n",
        "d_C = cuda.to_device(h_C)\n",
        "\n",
        "# -----------------------------\n",
        "# Launch configuration\n",
        "# -----------------------------\n",
        "threads_per_block = (16, 16)\n",
        "blocks_per_grid_x = (N + threads_per_block[0] - 1) // threads_per_block[0]\n",
        "blocks_per_grid_y = (N + threads_per_block[1] - 1) // threads_per_block[1]\n",
        "blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
        "\n",
        "# Launch kernel\n",
        "matrixMul[blocks_per_grid, threads_per_block](d_A, d_B, d_C)\n",
        "\n",
        "# Copy back\n",
        "d_C.copy_to_host(h_C)\n",
        "\n",
        "# Output\n",
        "print(\"C[0][0] =\", h_C[0, 0])"
      ],
      "metadata": {
        "id": "ZF99K8eFRDTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c171a4f-ebab-427c-ae54-f3a7bb49c9f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C[0][0] = 16.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numba_cuda/numba/cuda/dispatcher.py:697: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install numba cupy-cuda12x cudf-cu12 --extra-index-url=https://pypi.nvidia.com"
      ],
      "metadata": {
        "id": "sCpG9aP51PwB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Q5\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import cudf\n",
        "from numba import cuda\n",
        "import time\n",
        "\n",
        "# ------------------------------------------------\n",
        "# Problem size\n",
        "# ------------------------------------------------\n",
        "N = 5_000_000\n",
        "\n",
        "# ------------------------------------------------\n",
        "# Initialize data\n",
        "# ------------------------------------------------\n",
        "h_A = np.random.rand(N).astype(np.float32)\n",
        "h_B = np.random.rand(N).astype(np.float32)\n",
        "\n",
        "# =================================================\n",
        "# ✅ 1. CPU Sequential (NumPy)\n",
        "# =================================================\n",
        "start = time.time()\n",
        "h_C_cpu = h_A + h_B\n",
        "cpu_time = time.time() - start\n",
        "\n",
        "print(\"CPU Time:\", cpu_time)\n",
        "\n",
        "# =================================================\n",
        "# ✅ 2. CUDA Kernel (Numba)\n",
        "# =================================================\n",
        "@cuda.jit\n",
        "def vecAdd(A, B, C):\n",
        "    i = cuda.grid(1)\n",
        "    if i < A.size:\n",
        "        C[i] = A[i] + B[i]\n",
        "\n",
        "# Copy to device\n",
        "d_A = cuda.to_device(h_A)\n",
        "d_B = cuda.to_device(h_B)\n",
        "d_C = cuda.device_array_like(h_A)\n",
        "\n",
        "threads = 256\n",
        "blocks = (N + threads - 1) // threads\n",
        "\n",
        "start = time.time()\n",
        "vecAdd[blocks, threads](d_A, d_B, d_C)\n",
        "cuda.synchronize()\n",
        "cuda_time = time.time() - start\n",
        "\n",
        "h_C_cuda = d_C.copy_to_host()\n",
        "\n",
        "print(\"CUDA Kernel Time:\", cuda_time)\n",
        "\n",
        "# =================================================\n",
        "# ✅ 3. Thrust-like (CuPy GPU vectorized)\n",
        "# =================================================\n",
        "cp_A = cp.asarray(h_A)\n",
        "cp_B = cp.asarray(h_B)\n",
        "\n",
        "start = time.time()\n",
        "cp_C = cp_A + cp_B\n",
        "cp.cuda.Stream.null.synchronize()\n",
        "thrust_time = time.time() - start\n",
        "\n",
        "print(\"Thrust (CuPy) Time:\", thrust_time)\n",
        "\n",
        "# =================================================\n",
        "# ✅ 4. RAPIDS (cuDF)\n",
        "# =================================================\n",
        "gdf = cudf.DataFrame({\n",
        "    \"A\": h_A,\n",
        "    \"B\": h_B\n",
        "})\n",
        "\n",
        "start = time.time()\n",
        "gdf[\"C\"] = gdf[\"A\"] + gdf[\"B\"]\n",
        "rapids_time = time.time() - start\n",
        "\n",
        "print(\"RAPIDS Time:\", rapids_time)\n",
        "\n",
        "# =================================================\n",
        "# Summary\n",
        "# =================================================\n",
        "print(\"\\n===== SUMMARY =====\")\n",
        "print(f\"CPU Time       : {cpu_time:.6f} sec\")\n",
        "print(f\"CUDA Kernel    : {cuda_time:.6f} sec\")\n",
        "print(f\"Thrust (CuPy)  : {thrust_time:.6f} sec\")\n",
        "print(f\"RAPIDS (cuDF)  : {rapids_time:.6f} sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU7rtzpm1j8-",
        "outputId": "70d41184-4b07-4279-b236-174ba9a274dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Time: 0.012083053588867188\n",
            "CUDA Kernel Time: 0.1880950927734375\n",
            "Thrust (CuPy) Time: 0.00116729736328125\n",
            "RAPIDS Time: 0.005854368209838867\n",
            "\n",
            "===== SUMMARY =====\n",
            "CPU Time       : 0.012083 sec\n",
            "CUDA Kernel    : 0.188095 sec\n",
            "Thrust (CuPy)  : 0.001167 sec\n",
            "RAPIDS (cuDF)  : 0.005854 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Q6\n",
        "!pip -q install cupy-cuda12x\n",
        "import cupy as cp\n",
        "\n",
        "# --------------------------------\n",
        "# Step 1: Create vector on GPU\n",
        "# --------------------------------\n",
        "d_vec = cp.arange(1, 11, dtype=cp.int32)  # [1..10]\n",
        "\n",
        "# --------------------------------\n",
        "# Step 2: Compute sum on GPU\n",
        "# --------------------------------\n",
        "gpu_sum = cp.sum(d_vec)\n",
        "\n",
        "# --------------------------------\n",
        "# Step 3: Print result\n",
        "# --------------------------------\n",
        "print(\"Vector:\", d_vec)\n",
        "print(\"Sum =\", int(gpu_sum))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzwdXsMx2bxo",
        "outputId": "020694f9-01f8-4e80-9d5a-5a4b50d37dda"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector: [ 1  2  3  4  5  6  7  8  9 10]\n",
            "Sum = 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Q7\n",
        "!pip -q install cupy-cuda12x\n",
        "import cupy as cp\n",
        "\n",
        "d_vec = cp.array([7, 2, 9, 1, 5, 3, 8, 4], dtype=cp.int32)\n",
        "\n",
        "print(\"Before sorting:\")\n",
        "print(d_vec)\n",
        "\n",
        "# FIX: store the result\n",
        "d_vec = cp.sort(d_vec)\n",
        "\n",
        "print(\"\\nAfter sorting:\")\n",
        "print(d_vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m7ErNni20qA",
        "outputId": "2647b0ea-5c06-432a-c964-83e6e61e96dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before sorting:\n",
            "[7 2 9 1 5 3 8 4]\n",
            "\n",
            "After sorting:\n",
            "[1 2 3 4 5 7 8 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6AeMJutr3fOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}